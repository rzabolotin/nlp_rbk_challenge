{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a95f2bda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "sns.set_theme()\n",
    "nltk.download(\"stopwords\");\n",
    "\n",
    "RANDOM_STATE = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da71772",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train_dataset_train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"data/test_dataset_test.csv\", index_col=0)\n",
    "\n",
    "train_df[\"is_train\"] = 1\n",
    "test_df[\"is_train\"] = 0\n",
    "\n",
    "df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac2329f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RBKpreprocessor(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self._vectorizer_tags = TfidfVectorizer()\n",
    "        self._vectorizer_authors = TfidfVectorizer()\n",
    "        self._category_ohe = LabelEncoder()\n",
    "        self._category_from_title_ohe = LabelEncoder()\n",
    "        self._stop_words = stopwords.words(\"russian\")\n",
    "        self._stemmer = SnowballStemmer(\"russian\")\n",
    "        self._vectorizer_title = TfidfVectorizer()\n",
    "        \n",
    "        \n",
    "    def _clean_list(self, title):\n",
    "        return(title.\n",
    "           replace(\"[\", \"\").\n",
    "           replace(\"]\", \"\").\n",
    "           replace(\".\", \"\").\n",
    "           replace(\"'\", \"\").\n",
    "           replace(\",\", \" \")\n",
    "          )\n",
    "    \n",
    "    def _clean_title(self, title):\n",
    "        if title.find(\"\\n\")>0:\n",
    "            title = title[0:title.find(\"\\n\\n\")].lower()\n",
    "        title = \" \".join([self._stemmer.stem(w) for w in title.split() if w not in self._stop_words])\n",
    "        return title\n",
    "\n",
    "    def _find_category_in_title(self, title):\n",
    "        if title.find(\"\\n\")>0:\n",
    "            title = title[title.find(\"\\n\\n\"):].lower().strip()\n",
    "        else:\n",
    "            title = \"\"\n",
    "        if \",\" in title:\n",
    "            title = title[0:title.index(\",\")]\n",
    "        else:\n",
    "            title = \"\"\n",
    "\n",
    "        return title\n",
    "    \n",
    "    def fit(self, df):\n",
    "        self._category_ohe.fit(df.category.values.reshape(-1,1))\n",
    "        \n",
    "        authors_clean = df.authors.apply(self._clean_list)\n",
    "        tags_clean = df.tags.apply(self._clean_list)\n",
    "        self._vectorizer_tags.fit(tags_clean)\n",
    "        self._vectorizer_authors.fit(authors_clean);\n",
    "        \n",
    "        title_clean = df.title.apply(self._clean_title)\n",
    "        category_from_title =  df.title.apply(self._find_category_in_title)\n",
    "        self._category_from_title_ohe.fit(category_from_title.values.reshape(-1,1))\n",
    "        self._vectorizer_title.fit(title_clean)\n",
    "        \n",
    "        return(self)\n",
    "        \n",
    "        \n",
    "    def transform(self, df):\n",
    "        ctr_zero = (df.ctr == 0)\n",
    "        ctr_log = np.log(df.ctr)\n",
    "        mean_ctr_log = np.mean(ctr_log.values, where=(ctr_log != -np.inf))\n",
    "        ctr_log = np.where(df[\"ctr\"] == 0, mean_ctr_log, ctr_log)\n",
    "        \n",
    "        category_sparse = self._category_ohe.transform(df.category.values)\n",
    "        \n",
    "        authors_clean = df.authors.apply(self._clean_list)\n",
    "        tags_clean = df.tags.apply(self._clean_list)\n",
    "        \n",
    "        authors_count = authors_clean.apply(lambda x: len(x.split()))\n",
    "        tags_count = tags_clean.apply(lambda x: len(x.split()))\n",
    "        \n",
    "        tags_sparse = self._vectorizer_tags.transform(tags_clean)\n",
    "        authors_sparse = self._vectorizer_authors.transform(authors_clean)\n",
    "        \n",
    "        publish_date = pd.to_datetime(df.publish_date)\n",
    "        publish_year = publish_date.dt.year * 100 + publish_date.dt.month\n",
    "        publish_day = publish_date.dt.day\n",
    "        publish_weekday = publish_date.dt.weekday\n",
    "        publish_hour = publish_date.dt.hour\n",
    "        \n",
    "        title_clean = df.title.apply(self._clean_title)\n",
    "        title_sparse  = self._vectorizer_title.transform(title_clean)\n",
    "        \n",
    "        category_from_title =  df.title.apply(self._find_category_in_title)\n",
    "        category_from_title_sparse = self._category_from_title_ohe.transform(category_from_title.values)\n",
    "        \n",
    "        return hstack([\n",
    "            category_sparse.reshape(-1,1),\n",
    "            category_from_title_sparse.reshape(-1,1),\n",
    "            ctr_zero.values[:,None],\n",
    "            ctr_log[:,None],\n",
    "            authors_count.values[:,None],\n",
    "            tags_count.values[:,None],\n",
    "            tags_sparse,\n",
    "            authors_sparse,\n",
    "            publish_year.values[:,None],\n",
    "            publish_day.values[:,None],\n",
    "            publish_weekday.values[:,None],\n",
    "            publish_hour.values[:,None],\n",
    "            title_sparse            \n",
    "        ])\n",
    "        \n",
    "def my_metric(y_real, preds, detail=True):\n",
    "    overall = (\n",
    "            0.4*r2_score(y_real.iloc[:,0], preds[:,0]) + \n",
    "            0.3*r2_score(y_real.iloc[:,1], preds[:,1]) + \n",
    "            0.3*r2_score(y_real.iloc[:,2], preds[:,2])\n",
    "        )\n",
    "    \n",
    "    if not detail:\n",
    "        return overall\n",
    "    else:\n",
    "        return (\n",
    "            overall,\n",
    "            0.4*r2_score(y_real.iloc[:,0], preds[:,0]), \n",
    "            0.3*r2_score(y_real.iloc[:,1], preds[:,1]), \n",
    "            0.3*r2_score(y_real.iloc[:,2], preds[:,2])\n",
    "        )\n",
    "    \n",
    "def write_down_predictions(preds, output_file = \"output.csv\"):\n",
    "    solution = pd.read_csv(\"data\\sample_solution.csv\")\n",
    "    solution.iloc[:,1:4] = preds\n",
    "    solution.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea16e5b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RBKpreprocessor(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self._vectorizer_tags = TfidfVectorizer()\n",
    "        self._vectorizer_authors = TfidfVectorizer()\n",
    "        self._category_ohe = OneHotEncoder()\n",
    "        self._category_from_title_ohe = OneHotEncoder()\n",
    "        self._stop_words = stopwords.words(\"russian\")\n",
    "        self._stemmer = SnowballStemmer(\"russian\")\n",
    "        self._vectorizer_title = TfidfVectorizer()\n",
    "        \n",
    "        \n",
    "    def _clean_list(self, title):\n",
    "        return(title.\n",
    "           replace(\"[\", \"\").\n",
    "           replace(\"]\", \"\").\n",
    "           replace(\".\", \"\").\n",
    "           replace(\"'\", \"\").\n",
    "           replace(\",\", \" \")\n",
    "          )\n",
    "    \n",
    "    def _clean_title(self, title):\n",
    "        if title.find(\"\\n\")>0:\n",
    "            title = title[0:title.find(\"\\n\\n\")].lower()\n",
    "        title = \" \".join([self._stemmer.stem(w) for w in title.split() if w not in self._stop_words])\n",
    "        return title\n",
    "\n",
    "    def _find_category_in_title(self, title):\n",
    "        if title.find(\"\\n\")>0:\n",
    "            title = title[title.find(\"\\n\\n\"):].lower().strip()\n",
    "        else:\n",
    "            title = \"\"\n",
    "        if \",\" in title:\n",
    "            title = title[0:title.index(\",\")]\n",
    "        else:\n",
    "            title = \"\"\n",
    "\n",
    "        return title\n",
    "    \n",
    "    def fit(self, df):\n",
    "        self._category_ohe.fit(df.category.values.reshape(-1,1))\n",
    "        \n",
    "        authors_clean = df.authors.apply(self._clean_list)\n",
    "        tags_clean = df.tags.apply(self._clean_list)\n",
    "        self._vectorizer_tags.fit(tags_clean)\n",
    "        self._vectorizer_authors.fit(authors_clean);\n",
    "        \n",
    "        title_clean = df.title.apply(self._clean_title)\n",
    "        category_from_title =  df.title.apply(self._find_category_in_title)\n",
    "        self._category_from_title_ohe.fit(category_from_title.values.reshape(-1,1))\n",
    "        self._vectorizer_title.fit(title_clean)\n",
    "        \n",
    "        return(self)\n",
    "        \n",
    "        \n",
    "    def transform(self, df):\n",
    "        ctr_zero = (df.ctr == 0)\n",
    "        ctr_log = np.log(df.ctr)\n",
    "        mean_ctr_log = np.mean(ctr_log.values, where=(ctr_log != -np.inf))\n",
    "        ctr_log = np.where(df[\"ctr\"] == 0, mean_ctr_log, ctr_log)\n",
    "        \n",
    "        category_sparse = self._category_ohe.transform(df.category.values.reshape(-1,1))\n",
    "        \n",
    "        authors_clean = df.authors.apply(self._clean_list)\n",
    "        tags_clean = df.tags.apply(self._clean_list)\n",
    "        \n",
    "        authors_count = authors_clean.apply(lambda x: len(x.split()))\n",
    "        tags_count = tags_clean.apply(lambda x: len(x.split()))\n",
    "        \n",
    "        tags_sparse = self._vectorizer_tags.transform(tags_clean)\n",
    "        authors_sparse = self._vectorizer_authors.transform(authors_clean)\n",
    "        \n",
    "        publish_date = pd.to_datetime(df.publish_date)\n",
    "        publish_year = publish_date.dt.year * 100 + publish_date.dt.month\n",
    "        publish_day = publish_date.dt.day\n",
    "        publish_weekday = publish_date.dt.weekday\n",
    "        publish_hour = publish_date.dt.hour\n",
    "        \n",
    "        title_clean = df.title.apply(self._clean_title)\n",
    "        title_sparse  = self._vectorizer_title.transform(title_clean)\n",
    "        \n",
    "        category_from_title =  df.title.apply(self._find_category_in_title)\n",
    "        category_from_title_sparse = self._category_from_title_ohe.transform(category_from_title.values.reshape(-1,1))\n",
    "        \n",
    "        return hstack([\n",
    "            ctr_zero.values[:,None],\n",
    "            ctr_log[:,None],\n",
    "            category_sparse,\n",
    "            authors_count.values[:,None],\n",
    "            tags_count.values[:,None],\n",
    "            tags_sparse,\n",
    "            authors_sparse,\n",
    "            publish_year.values[:,None],\n",
    "            publish_day.values[:,None],\n",
    "            publish_weekday.values[:,None],\n",
    "            publish_hour.values[:,None],\n",
    "            title_sparse,\n",
    "            category_from_title_sparse\n",
    "        ])\n",
    "        \n",
    "def my_metric(y_real, preds, detail=True):\n",
    "    overall = (\n",
    "            0.4*r2_score(y_real.iloc[:,0], preds[:,0]) + \n",
    "            0.3*r2_score(y_real.iloc[:,1], preds[:,1]) + \n",
    "            0.3*r2_score(y_real.iloc[:,2], preds[:,2])\n",
    "        )\n",
    "    \n",
    "    if not detail:\n",
    "        return overall\n",
    "    else:\n",
    "        return (\n",
    "            overall,\n",
    "            0.4*r2_score(y_real.iloc[:,0], preds[:,0]), \n",
    "            0.3*r2_score(y_real.iloc[:,1], preds[:,1]), \n",
    "            0.3*r2_score(y_real.iloc[:,2], preds[:,2])\n",
    "        )\n",
    "    \n",
    "def write_down_predictions(preds, output_file = \"output.csv\"):\n",
    "    solution = pd.read_csv(\"data\\sample_solution.csv\")\n",
    "    solution.iloc[:,1:4] = preds\n",
    "    solution.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a144c93f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.66 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RBKpreprocessor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preprocess = RBKpreprocessor()\n",
    "preprocess.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f996377",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# valid_train_df, valid_test_df = train_test_split(train_df, test_size=0.2, random_state=RANDOM_STATE, shuffle=True)\n",
    "\n",
    "\n",
    "# X_train = preprocess.transform(valid_train_df)\n",
    "# y_train = valid_train_df[[\"views\", \"depth\", \"full_reads_percent\"]]\n",
    "\n",
    "# X_test = preprocess.transform(valid_test_df)\n",
    "# y_test = valid_test_df[[\"views\", \"depth\", \"full_reads_percent\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39809eed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tuning for catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d776c7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Soft\\Anaconda\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = preprocess.transform(train_df)\n",
    "y_train = train_df[[\"views\", \"depth\", \"full_reads_percent\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a14015",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(iterations=120,\n",
    "                          early_stopping_rounds=30,\n",
    "                          random_seed=RANDOM_STATE,\n",
    "                          eval_metric=\"R2\",\n",
    "                          loss_function=\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be0b9804",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "GOAL_NUM = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c56d5a5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params = {'depth':[7,8,9,10],\n",
    "          'learning_rate' : [0.05, 0.1]\n",
    "         }\n",
    "clf = RandomizedSearchCV(model, params, random_state=RANDOM_STATE, n_iter=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6ee47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "search = clf.fit(X_train, \n",
    "          y_train.iloc[:,GOAL_NUM]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde9c088",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'depth': 8}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "675e9293",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.47</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>{'learning_rate': 0.05, 'depth': 7}</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>117.72</td>\n",
       "      <td>36.20</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 7}</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.27</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207.34</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "      <td>{'learning_rate': 0.05, 'depth': 8}</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>265.14</td>\n",
       "      <td>27.81</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 8}</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>428.30</td>\n",
       "      <td>42.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9</td>\n",
       "      <td>{'learning_rate': 0.05, 'depth': 9}</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>564.37</td>\n",
       "      <td>29.57</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 9}</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1,219.94</td>\n",
       "      <td>39.24</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.05, 'depth': 10}</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.24</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1,003.05</td>\n",
       "      <td>237.18</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 10}</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          87.47          1.40             0.42            0.15   \n",
       "1         117.72         36.20             0.55            0.10   \n",
       "2         207.34          1.40             0.39            0.04   \n",
       "3         265.14         27.81             0.89            0.54   \n",
       "4         428.30         42.72             0.72            0.16   \n",
       "5         564.37         29.57             1.18            0.31   \n",
       "6       1,219.94         39.24             0.97            0.32   \n",
       "7       1,003.05        237.18             0.39            0.15   \n",
       "\n",
       "  param_learning_rate param_depth                                params  \\\n",
       "0                0.05           7   {'learning_rate': 0.05, 'depth': 7}   \n",
       "1                0.10           7    {'learning_rate': 0.1, 'depth': 7}   \n",
       "2                0.05           8   {'learning_rate': 0.05, 'depth': 8}   \n",
       "3                0.10           8    {'learning_rate': 0.1, 'depth': 8}   \n",
       "4                0.05           9   {'learning_rate': 0.05, 'depth': 9}   \n",
       "5                0.10           9    {'learning_rate': 0.1, 'depth': 9}   \n",
       "6                0.05          10  {'learning_rate': 0.05, 'depth': 10}   \n",
       "7                0.10          10   {'learning_rate': 0.1, 'depth': 10}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0               0.44               0.53               0.38               0.04   \n",
       "1               0.49               0.58               0.42              -0.17   \n",
       "2               0.42               0.53               0.37              -0.26   \n",
       "3               0.47               0.59               0.42               0.08   \n",
       "4               0.46               0.53               0.38              -0.13   \n",
       "5               0.53               0.59               0.41              -0.06   \n",
       "6               0.46               0.55               0.38              -0.12   \n",
       "7               0.48               0.60               0.43              -0.09   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.44             0.37            0.17                4  \n",
       "1               0.46             0.36            0.27                5  \n",
       "2               0.47             0.31            0.29                8  \n",
       "3               0.52             0.42            0.18                1  \n",
       "4               0.46             0.34            0.24                6  \n",
       "5               0.46             0.38            0.23                2  \n",
       "6               0.41             0.33            0.24                7  \n",
       "7               0.50             0.38            0.24                3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "620bc800",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 8 is smaller than n_iter=20. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1793380\ttotal: 1.07s\tremaining: 2m 7s\n",
      "1:\tlearn: 0.3117821\ttotal: 1.97s\tremaining: 1m 56s\n",
      "2:\tlearn: 0.4105699\ttotal: 2.97s\tremaining: 1m 55s\n",
      "3:\tlearn: 0.4862333\ttotal: 3.97s\tremaining: 1m 55s\n",
      "4:\tlearn: 0.5470395\ttotal: 4.79s\tremaining: 1m 50s\n",
      "5:\tlearn: 0.5973565\ttotal: 5.64s\tremaining: 1m 47s\n",
      "6:\tlearn: 0.6374325\ttotal: 6.61s\tremaining: 1m 46s\n",
      "7:\tlearn: 0.6690178\ttotal: 7.55s\tremaining: 1m 45s\n",
      "8:\tlearn: 0.6907904\ttotal: 8.43s\tremaining: 1m 43s\n",
      "9:\tlearn: 0.7097812\ttotal: 9.29s\tremaining: 1m 42s\n",
      "10:\tlearn: 0.7237613\ttotal: 10.3s\tremaining: 1m 41s\n",
      "11:\tlearn: 0.7364248\ttotal: 11.2s\tremaining: 1m 41s\n",
      "12:\tlearn: 0.7452690\ttotal: 12.2s\tremaining: 1m 40s\n",
      "13:\tlearn: 0.7551922\ttotal: 13.1s\tremaining: 1m 39s\n",
      "14:\tlearn: 0.7568141\ttotal: 14.1s\tremaining: 1m 38s\n",
      "15:\tlearn: 0.7589324\ttotal: 15s\tremaining: 1m 37s\n",
      "16:\tlearn: 0.7606947\ttotal: 15.9s\tremaining: 1m 36s\n",
      "17:\tlearn: 0.7689932\ttotal: 16.8s\tremaining: 1m 35s\n",
      "18:\tlearn: 0.7742968\ttotal: 17.8s\tremaining: 1m 34s\n",
      "19:\tlearn: 0.7754859\ttotal: 18.6s\tremaining: 1m 33s\n",
      "20:\tlearn: 0.7769560\ttotal: 19.5s\tremaining: 1m 31s\n",
      "21:\tlearn: 0.7781864\ttotal: 20.4s\tremaining: 1m 30s\n",
      "22:\tlearn: 0.7791050\ttotal: 21.3s\tremaining: 1m 29s\n",
      "23:\tlearn: 0.7800531\ttotal: 22.1s\tremaining: 1m 28s\n",
      "24:\tlearn: 0.7863317\ttotal: 23s\tremaining: 1m 27s\n",
      "25:\tlearn: 0.7897797\ttotal: 23.9s\tremaining: 1m 26s\n",
      "26:\tlearn: 0.7907402\ttotal: 24.9s\tremaining: 1m 25s\n",
      "27:\tlearn: 0.7915465\ttotal: 25.7s\tremaining: 1m 24s\n",
      "28:\tlearn: 0.7946506\ttotal: 26.5s\tremaining: 1m 23s\n",
      "29:\tlearn: 0.7954717\ttotal: 27.4s\tremaining: 1m 22s\n",
      "30:\tlearn: 0.7963062\ttotal: 28.4s\tremaining: 1m 21s\n",
      "31:\tlearn: 0.7969489\ttotal: 29.4s\tremaining: 1m 20s\n",
      "32:\tlearn: 0.8014213\ttotal: 30.2s\tremaining: 1m 19s\n",
      "33:\tlearn: 0.8040706\ttotal: 31.2s\tremaining: 1m 18s\n",
      "34:\tlearn: 0.8074225\ttotal: 32.1s\tremaining: 1m 17s\n",
      "35:\tlearn: 0.8081811\ttotal: 32.9s\tremaining: 1m 16s\n",
      "36:\tlearn: 0.8088386\ttotal: 33.8s\tremaining: 1m 15s\n",
      "37:\tlearn: 0.8138259\ttotal: 34.7s\tremaining: 1m 14s\n",
      "38:\tlearn: 0.8145566\ttotal: 35.6s\tremaining: 1m 13s\n",
      "39:\tlearn: 0.8164598\ttotal: 36.5s\tremaining: 1m 12s\n",
      "40:\tlearn: 0.8170370\ttotal: 37.5s\tremaining: 1m 12s\n",
      "41:\tlearn: 0.8209439\ttotal: 38.4s\tremaining: 1m 11s\n",
      "42:\tlearn: 0.8213690\ttotal: 39.3s\tremaining: 1m 10s\n",
      "43:\tlearn: 0.8240319\ttotal: 40.3s\tremaining: 1m 9s\n",
      "44:\tlearn: 0.8246268\ttotal: 41.3s\tremaining: 1m 8s\n",
      "45:\tlearn: 0.8265944\ttotal: 42.5s\tremaining: 1m 8s\n",
      "46:\tlearn: 0.8270965\ttotal: 43.4s\tremaining: 1m 7s\n",
      "47:\tlearn: 0.8275623\ttotal: 44.5s\tremaining: 1m 6s\n",
      "48:\tlearn: 0.8281232\ttotal: 45.5s\tremaining: 1m 5s\n",
      "49:\tlearn: 0.8285834\ttotal: 46.4s\tremaining: 1m 4s\n",
      "50:\tlearn: 0.8304717\ttotal: 47.4s\tremaining: 1m 4s\n",
      "51:\tlearn: 0.8309241\ttotal: 48.4s\tremaining: 1m 3s\n",
      "52:\tlearn: 0.8313849\ttotal: 49.4s\tremaining: 1m 2s\n",
      "53:\tlearn: 0.8324828\ttotal: 50.7s\tremaining: 1m 1s\n",
      "54:\tlearn: 0.8329938\ttotal: 51.8s\tremaining: 1m 1s\n",
      "55:\tlearn: 0.8349799\ttotal: 53s\tremaining: 1m\n",
      "56:\tlearn: 0.8354876\ttotal: 54.1s\tremaining: 59.8s\n",
      "57:\tlearn: 0.8366923\ttotal: 55s\tremaining: 58.8s\n",
      "58:\tlearn: 0.8372255\ttotal: 55.8s\tremaining: 57.7s\n",
      "59:\tlearn: 0.8377499\ttotal: 56.8s\tremaining: 56.8s\n",
      "60:\tlearn: 0.8382935\ttotal: 57.7s\tremaining: 55.8s\n",
      "61:\tlearn: 0.8388557\ttotal: 58.6s\tremaining: 54.8s\n",
      "62:\tlearn: 0.8393306\ttotal: 59.6s\tremaining: 53.9s\n",
      "63:\tlearn: 0.8408495\ttotal: 1m\tremaining: 52.9s\n",
      "64:\tlearn: 0.8412640\ttotal: 1m 1s\tremaining: 52s\n",
      "65:\tlearn: 0.8417001\ttotal: 1m 2s\tremaining: 51s\n",
      "66:\tlearn: 0.8436726\ttotal: 1m 3s\tremaining: 50.2s\n",
      "67:\tlearn: 0.8441630\ttotal: 1m 4s\tremaining: 49.2s\n",
      "68:\tlearn: 0.8461671\ttotal: 1m 5s\tremaining: 48.3s\n",
      "69:\tlearn: 0.8469879\ttotal: 1m 6s\tremaining: 47.3s\n",
      "70:\tlearn: 0.8489520\ttotal: 1m 7s\tremaining: 46.3s\n",
      "71:\tlearn: 0.8504047\ttotal: 1m 7s\tremaining: 45.3s\n",
      "72:\tlearn: 0.8510667\ttotal: 1m 8s\tremaining: 44.3s\n",
      "73:\tlearn: 0.8523140\ttotal: 1m 9s\tremaining: 43.4s\n",
      "74:\tlearn: 0.8527103\ttotal: 1m 10s\tremaining: 42.4s\n",
      "75:\tlearn: 0.8530752\ttotal: 1m 11s\tremaining: 41.5s\n",
      "76:\tlearn: 0.8549007\ttotal: 1m 12s\tremaining: 40.5s\n",
      "77:\tlearn: 0.8553983\ttotal: 1m 13s\tremaining: 39.5s\n",
      "78:\tlearn: 0.8557765\ttotal: 1m 14s\tremaining: 38.5s\n",
      "79:\tlearn: 0.8566883\ttotal: 1m 15s\tremaining: 37.5s\n",
      "80:\tlearn: 0.8570172\ttotal: 1m 15s\tremaining: 36.5s\n",
      "81:\tlearn: 0.8580113\ttotal: 1m 16s\tremaining: 35.6s\n",
      "82:\tlearn: 0.8583306\ttotal: 1m 17s\tremaining: 34.6s\n",
      "83:\tlearn: 0.8588742\ttotal: 1m 18s\tremaining: 33.7s\n",
      "84:\tlearn: 0.8596726\ttotal: 1m 19s\tremaining: 32.7s\n",
      "85:\tlearn: 0.8602546\ttotal: 1m 20s\tremaining: 31.7s\n",
      "86:\tlearn: 0.8605573\ttotal: 1m 21s\tremaining: 30.8s\n",
      "87:\tlearn: 0.8608995\ttotal: 1m 21s\tremaining: 29.8s\n",
      "88:\tlearn: 0.8622688\ttotal: 1m 22s\tremaining: 28.9s\n",
      "89:\tlearn: 0.8625444\ttotal: 1m 23s\tremaining: 27.9s\n",
      "90:\tlearn: 0.8632345\ttotal: 1m 24s\tremaining: 27s\n",
      "91:\tlearn: 0.8642239\ttotal: 1m 25s\tremaining: 26s\n",
      "92:\tlearn: 0.8648360\ttotal: 1m 26s\tremaining: 25s\n",
      "93:\tlearn: 0.8650957\ttotal: 1m 27s\tremaining: 24.1s\n",
      "94:\tlearn: 0.8654863\ttotal: 1m 28s\tremaining: 23.2s\n",
      "95:\tlearn: 0.8660351\ttotal: 1m 28s\tremaining: 22.2s\n",
      "96:\tlearn: 0.8665592\ttotal: 1m 29s\tremaining: 21.3s\n",
      "97:\tlearn: 0.8668099\ttotal: 1m 30s\tremaining: 20.4s\n",
      "98:\tlearn: 0.8671318\ttotal: 1m 31s\tremaining: 19.4s\n",
      "99:\tlearn: 0.8673779\ttotal: 1m 32s\tremaining: 18.5s\n",
      "100:\tlearn: 0.8681513\ttotal: 1m 33s\tremaining: 17.6s\n",
      "101:\tlearn: 0.8687193\ttotal: 1m 34s\tremaining: 16.6s\n",
      "102:\tlearn: 0.8704184\ttotal: 1m 35s\tremaining: 15.7s\n",
      "103:\tlearn: 0.8706517\ttotal: 1m 35s\tremaining: 14.8s\n",
      "104:\tlearn: 0.8708731\ttotal: 1m 36s\tremaining: 13.8s\n",
      "105:\tlearn: 0.8716997\ttotal: 1m 37s\tremaining: 12.9s\n",
      "106:\tlearn: 0.8719130\ttotal: 1m 38s\tremaining: 12s\n",
      "107:\tlearn: 0.8722443\ttotal: 1m 39s\tremaining: 11.1s\n",
      "108:\tlearn: 0.8730204\ttotal: 1m 40s\tremaining: 10.1s\n",
      "109:\tlearn: 0.8732214\ttotal: 1m 41s\tremaining: 9.21s\n",
      "110:\tlearn: 0.8745122\ttotal: 1m 42s\tremaining: 8.29s\n",
      "111:\tlearn: 0.8753041\ttotal: 1m 43s\tremaining: 7.37s\n",
      "112:\tlearn: 0.8754936\ttotal: 1m 44s\tremaining: 6.45s\n",
      "113:\tlearn: 0.8758363\ttotal: 1m 45s\tremaining: 5.53s\n",
      "114:\tlearn: 0.8765855\ttotal: 1m 45s\tremaining: 4.6s\n",
      "115:\tlearn: 0.8768551\ttotal: 1m 46s\tremaining: 3.68s\n",
      "116:\tlearn: 0.8770484\ttotal: 1m 47s\tremaining: 2.76s\n",
      "117:\tlearn: 0.8772367\ttotal: 1m 48s\tremaining: 1.84s\n",
      "118:\tlearn: 0.8774126\ttotal: 1m 49s\tremaining: 919ms\n",
      "119:\tlearn: 0.8779061\ttotal: 1m 50s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.15, 'depth': 10}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOAL_NUM = 1\n",
    "params = {'depth':[7,8,9,10],\n",
    "          'learning_rate' : [0.1, 0.15]\n",
    "         } \n",
    "clf = RandomizedSearchCV(model, params, random_state=RANDOM_STATE, n_iter=20, n_jobs=3)\n",
    "search1 = clf.fit(X_train, \n",
    "          y_train.iloc[:,GOAL_NUM]\n",
    "         )\n",
    "search1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7529cd3a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.12</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 7}</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.39</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.15</td>\n",
       "      <td>7</td>\n",
       "      <td>{'learning_rate': 0.15, 'depth': 7}</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.43</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 8}</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.87</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>8</td>\n",
       "      <td>{'learning_rate': 0.15, 'depth': 8}</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166.50</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 9}</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>191.25</td>\n",
       "      <td>16.06</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>9</td>\n",
       "      <td>{'learning_rate': 0.15, 'depth': 9}</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>313.67</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 10}</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>235.74</td>\n",
       "      <td>69.76</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.15, 'depth': 10}</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          61.12          2.14             0.15            0.03   \n",
       "1          58.39          3.71             0.21            0.04   \n",
       "2          94.43          1.51             0.29            0.10   \n",
       "3          99.87          3.37             0.22            0.05   \n",
       "4         166.50          6.90             0.24            0.07   \n",
       "5         191.25         16.06             0.29            0.09   \n",
       "6         313.67         28.00             0.24            0.08   \n",
       "7         235.74         69.76             0.16            0.03   \n",
       "\n",
       "  param_learning_rate param_depth                                params  \\\n",
       "0                0.10           7    {'learning_rate': 0.1, 'depth': 7}   \n",
       "1                0.15           7   {'learning_rate': 0.15, 'depth': 7}   \n",
       "2                0.10           8    {'learning_rate': 0.1, 'depth': 8}   \n",
       "3                0.15           8   {'learning_rate': 0.15, 'depth': 8}   \n",
       "4                0.10           9    {'learning_rate': 0.1, 'depth': 9}   \n",
       "5                0.15           9   {'learning_rate': 0.15, 'depth': 9}   \n",
       "6                0.10          10   {'learning_rate': 0.1, 'depth': 10}   \n",
       "7                0.15          10  {'learning_rate': 0.15, 'depth': 10}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0               0.74               0.80               0.80               0.77   \n",
       "1               0.75               0.80               0.80               0.76   \n",
       "2               0.75               0.79               0.80               0.77   \n",
       "3               0.75               0.80               0.81               0.78   \n",
       "4               0.75               0.80               0.81               0.77   \n",
       "5               0.75               0.80               0.82               0.77   \n",
       "6               0.75               0.80               0.81               0.78   \n",
       "7               0.76               0.81               0.82               0.79   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.74             0.77            0.02                8  \n",
       "1               0.75             0.77            0.02                7  \n",
       "2               0.75             0.77            0.02                6  \n",
       "3               0.76             0.78            0.02                2  \n",
       "4               0.75             0.77            0.02                5  \n",
       "5               0.74             0.78            0.03                3  \n",
       "6               0.74             0.78            0.03                4  \n",
       "7               0.74             0.78            0.03                1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search1.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ccc332",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Soft\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 8 is smaller than n_iter=20. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0682912\ttotal: 697ms\tremaining: 1m 22s\n",
      "1:\tlearn: 0.1122100\ttotal: 1.48s\tremaining: 1m 27s\n",
      "2:\tlearn: 0.1572043\ttotal: 2.24s\tremaining: 1m 27s\n",
      "3:\tlearn: 0.1895488\ttotal: 3.16s\tremaining: 1m 31s\n",
      "4:\tlearn: 0.2209927\ttotal: 3.95s\tremaining: 1m 30s\n",
      "5:\tlearn: 0.2266515\ttotal: 4.71s\tremaining: 1m 29s\n",
      "6:\tlearn: 0.2318317\ttotal: 5.5s\tremaining: 1m 28s\n",
      "7:\tlearn: 0.2494058\ttotal: 6.43s\tremaining: 1m 30s\n",
      "8:\tlearn: 0.2538562\ttotal: 7.19s\tremaining: 1m 28s\n",
      "9:\tlearn: 0.2579687\ttotal: 8.03s\tremaining: 1m 28s\n",
      "10:\tlearn: 0.2737321\ttotal: 8.86s\tremaining: 1m 27s\n",
      "11:\tlearn: 0.2772531\ttotal: 9.73s\tremaining: 1m 27s\n",
      "12:\tlearn: 0.2805615\ttotal: 10.5s\tremaining: 1m 26s\n",
      "13:\tlearn: 0.2834666\ttotal: 11.3s\tremaining: 1m 25s\n",
      "14:\tlearn: 0.2932175\ttotal: 12.1s\tremaining: 1m 24s\n",
      "15:\tlearn: 0.2957963\ttotal: 13s\tremaining: 1m 24s\n",
      "16:\tlearn: 0.2980195\ttotal: 13.8s\tremaining: 1m 23s\n",
      "17:\tlearn: 0.3003324\ttotal: 14.6s\tremaining: 1m 22s\n",
      "18:\tlearn: 0.3126008\ttotal: 15.4s\tremaining: 1m 22s\n",
      "19:\tlearn: 0.3143604\ttotal: 16.3s\tremaining: 1m 21s\n",
      "20:\tlearn: 0.3271213\ttotal: 17.2s\tremaining: 1m 21s\n",
      "21:\tlearn: 0.3288857\ttotal: 18s\tremaining: 1m 20s\n",
      "22:\tlearn: 0.3410547\ttotal: 18.8s\tremaining: 1m 19s\n",
      "23:\tlearn: 0.3426536\ttotal: 19.7s\tremaining: 1m 18s\n",
      "24:\tlearn: 0.3441248\ttotal: 20.5s\tremaining: 1m 18s\n",
      "25:\tlearn: 0.3454135\ttotal: 21.3s\tremaining: 1m 17s\n",
      "26:\tlearn: 0.3466468\ttotal: 22.2s\tremaining: 1m 16s\n",
      "27:\tlearn: 0.3545226\ttotal: 23.1s\tremaining: 1m 15s\n",
      "28:\tlearn: 0.3613410\ttotal: 23.8s\tremaining: 1m 14s\n",
      "29:\tlearn: 0.3625205\ttotal: 24.6s\tremaining: 1m 13s\n",
      "30:\tlearn: 0.3635979\ttotal: 25.4s\tremaining: 1m 13s\n",
      "31:\tlearn: 0.3701702\ttotal: 26.3s\tremaining: 1m 12s\n",
      "32:\tlearn: 0.3710628\ttotal: 27.1s\tremaining: 1m 11s\n",
      "33:\tlearn: 0.3779836\ttotal: 27.8s\tremaining: 1m 10s\n",
      "34:\tlearn: 0.3788419\ttotal: 28.7s\tremaining: 1m 9s\n",
      "35:\tlearn: 0.3838603\ttotal: 29.5s\tremaining: 1m 8s\n",
      "36:\tlearn: 0.3944459\ttotal: 30.3s\tremaining: 1m 8s\n",
      "37:\tlearn: 0.3952015\ttotal: 31.1s\tremaining: 1m 7s\n",
      "38:\tlearn: 0.4009864\ttotal: 31.9s\tremaining: 1m 6s\n",
      "39:\tlearn: 0.4017012\ttotal: 32.8s\tremaining: 1m 5s\n",
      "40:\tlearn: 0.4084888\ttotal: 33.6s\tremaining: 1m 4s\n",
      "41:\tlearn: 0.4093096\ttotal: 34.4s\tremaining: 1m 3s\n",
      "42:\tlearn: 0.4119720\ttotal: 35.2s\tremaining: 1m 3s\n",
      "43:\tlearn: 0.4125630\ttotal: 36s\tremaining: 1m 2s\n",
      "44:\tlearn: 0.4203633\ttotal: 36.8s\tremaining: 1m 1s\n",
      "45:\tlearn: 0.4264065\ttotal: 37.6s\tremaining: 1m\n",
      "46:\tlearn: 0.4269121\ttotal: 38.3s\tremaining: 59.5s\n",
      "47:\tlearn: 0.4304178\ttotal: 39.2s\tremaining: 58.8s\n",
      "48:\tlearn: 0.4361783\ttotal: 40s\tremaining: 58s\n",
      "49:\tlearn: 0.4402496\ttotal: 40.8s\tremaining: 57.1s\n",
      "50:\tlearn: 0.4435497\ttotal: 41.5s\tremaining: 56.1s\n",
      "51:\tlearn: 0.4440648\ttotal: 42.4s\tremaining: 55.4s\n",
      "52:\tlearn: 0.4475221\ttotal: 43.2s\tremaining: 54.6s\n",
      "53:\tlearn: 0.4504440\ttotal: 44s\tremaining: 53.8s\n",
      "54:\tlearn: 0.4550914\ttotal: 44.4s\tremaining: 52.5s\n",
      "55:\tlearn: 0.4631798\ttotal: 45.2s\tremaining: 51.7s\n",
      "56:\tlearn: 0.4665273\ttotal: 46.1s\tremaining: 51s\n",
      "57:\tlearn: 0.4671618\ttotal: 46.9s\tremaining: 50.1s\n",
      "58:\tlearn: 0.4706984\ttotal: 47.7s\tremaining: 49.3s\n",
      "59:\tlearn: 0.4713124\ttotal: 48.5s\tremaining: 48.5s\n",
      "60:\tlearn: 0.4743344\ttotal: 49.4s\tremaining: 47.8s\n",
      "61:\tlearn: 0.4776957\ttotal: 50.3s\tremaining: 47s\n",
      "62:\tlearn: 0.4806371\ttotal: 51s\tremaining: 46.1s\n",
      "63:\tlearn: 0.4837383\ttotal: 51.8s\tremaining: 45.3s\n",
      "64:\tlearn: 0.4864033\ttotal: 52.7s\tremaining: 44.6s\n",
      "65:\tlearn: 0.4871036\ttotal: 53.5s\tremaining: 43.8s\n",
      "66:\tlearn: 0.4876922\ttotal: 54.3s\tremaining: 43s\n",
      "67:\tlearn: 0.4906949\ttotal: 55.2s\tremaining: 42.2s\n",
      "68:\tlearn: 0.4913221\ttotal: 56.2s\tremaining: 41.5s\n",
      "69:\tlearn: 0.4924427\ttotal: 57s\tremaining: 40.7s\n",
      "70:\tlearn: 0.4976019\ttotal: 57.8s\tremaining: 39.9s\n",
      "71:\tlearn: 0.5018440\ttotal: 58.6s\tremaining: 39.1s\n",
      "72:\tlearn: 0.5025348\ttotal: 59.5s\tremaining: 38.3s\n",
      "73:\tlearn: 0.5070270\ttotal: 1m\tremaining: 37.5s\n",
      "74:\tlearn: 0.5108077\ttotal: 1m 1s\tremaining: 36.7s\n",
      "75:\tlearn: 0.5129526\ttotal: 1m 1s\tremaining: 35.9s\n",
      "76:\tlearn: 0.5160685\ttotal: 1m 2s\tremaining: 35.1s\n",
      "77:\tlearn: 0.5173324\ttotal: 1m 3s\tremaining: 34.3s\n",
      "78:\tlearn: 0.5201762\ttotal: 1m 4s\tremaining: 33.4s\n",
      "79:\tlearn: 0.5234126\ttotal: 1m 5s\tremaining: 32.7s\n",
      "80:\tlearn: 0.5254177\ttotal: 1m 6s\tremaining: 31.9s\n",
      "81:\tlearn: 0.5259982\ttotal: 1m 7s\tremaining: 31.1s\n",
      "82:\tlearn: 0.5289274\ttotal: 1m 7s\tremaining: 30.2s\n",
      "83:\tlearn: 0.5319861\ttotal: 1m 8s\tremaining: 29.5s\n",
      "84:\tlearn: 0.5385968\ttotal: 1m 9s\tremaining: 28.7s\n",
      "85:\tlearn: 0.5402043\ttotal: 1m 10s\tremaining: 27.8s\n",
      "86:\tlearn: 0.5416224\ttotal: 1m 11s\tremaining: 27s\n",
      "87:\tlearn: 0.5447906\ttotal: 1m 12s\tremaining: 26.2s\n",
      "88:\tlearn: 0.5453170\ttotal: 1m 12s\tremaining: 25.4s\n",
      "89:\tlearn: 0.5491954\ttotal: 1m 13s\tremaining: 24.6s\n",
      "90:\tlearn: 0.5512257\ttotal: 1m 14s\tremaining: 23.8s\n",
      "91:\tlearn: 0.5535208\ttotal: 1m 15s\tremaining: 23s\n",
      "92:\tlearn: 0.5557496\ttotal: 1m 16s\tremaining: 22.2s\n",
      "93:\tlearn: 0.5574573\ttotal: 1m 17s\tremaining: 21.3s\n",
      "94:\tlearn: 0.5585778\ttotal: 1m 17s\tremaining: 20.5s\n",
      "95:\tlearn: 0.5607795\ttotal: 1m 18s\tremaining: 19.7s\n",
      "96:\tlearn: 0.5640717\ttotal: 1m 19s\tremaining: 18.8s\n",
      "97:\tlearn: 0.5645336\ttotal: 1m 20s\tremaining: 18s\n",
      "98:\tlearn: 0.5653252\ttotal: 1m 20s\tremaining: 17.2s\n",
      "99:\tlearn: 0.5666539\ttotal: 1m 21s\tremaining: 16.4s\n",
      "100:\tlearn: 0.5678917\ttotal: 1m 22s\tremaining: 15.5s\n",
      "101:\tlearn: 0.5682949\ttotal: 1m 23s\tremaining: 14.7s\n",
      "102:\tlearn: 0.5706763\ttotal: 1m 24s\tremaining: 13.9s\n",
      "103:\tlearn: 0.5722336\ttotal: 1m 24s\tremaining: 13.1s\n",
      "104:\tlearn: 0.5735223\ttotal: 1m 25s\tremaining: 12.3s\n",
      "105:\tlearn: 0.5749099\ttotal: 1m 26s\tremaining: 11.4s\n",
      "106:\tlearn: 0.5756173\ttotal: 1m 27s\tremaining: 10.6s\n",
      "107:\tlearn: 0.5766184\ttotal: 1m 28s\tremaining: 9.8s\n",
      "108:\tlearn: 0.5791027\ttotal: 1m 28s\tremaining: 8.98s\n",
      "109:\tlearn: 0.5814881\ttotal: 1m 29s\tremaining: 8.17s\n",
      "110:\tlearn: 0.5828662\ttotal: 1m 30s\tremaining: 7.35s\n",
      "111:\tlearn: 0.5850509\ttotal: 1m 31s\tremaining: 6.53s\n",
      "112:\tlearn: 0.5860226\ttotal: 1m 32s\tremaining: 5.72s\n",
      "113:\tlearn: 0.5872692\ttotal: 1m 33s\tremaining: 4.91s\n",
      "114:\tlearn: 0.5881859\ttotal: 1m 33s\tremaining: 4.09s\n",
      "115:\tlearn: 0.5900959\ttotal: 1m 34s\tremaining: 3.27s\n",
      "116:\tlearn: 0.5916194\ttotal: 1m 35s\tremaining: 2.45s\n",
      "117:\tlearn: 0.5930548\ttotal: 1m 36s\tremaining: 1.64s\n",
      "118:\tlearn: 0.5939516\ttotal: 1m 37s\tremaining: 818ms\n",
      "119:\tlearn: 0.5950735\ttotal: 1m 38s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.15, 'depth': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOAL_NUM = 2\n",
    "params = {'depth':[7,8,9,10],\n",
    "          'learning_rate' : [0.1, 0.15]\n",
    "         }\n",
    "clf = RandomizedSearchCV(model, params, random_state=RANDOM_STATE, n_iter=20, n_jobs=3)\n",
    "\n",
    "search2 = clf.fit(X_train, \n",
    "          y_train.iloc[:,GOAL_NUM]\n",
    "         )\n",
    "search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d9edae4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.80</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 7}</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.25</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>7</td>\n",
       "      <td>{'learning_rate': 0.15, 'depth': 7}</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.62</td>\n",
       "      <td>1.81</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 8}</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.06</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.50</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.15</td>\n",
       "      <td>8</td>\n",
       "      <td>{'learning_rate': 0.15, 'depth': 8}</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 9}</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95.80</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>9</td>\n",
       "      <td>{'learning_rate': 0.15, 'depth': 9}</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>213.46</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.1, 'depth': 10}</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>185.09</td>\n",
       "      <td>40.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.15, 'depth': 10}</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          29.80          0.36             0.13            0.03   \n",
       "1          31.25          2.54             0.12            0.05   \n",
       "2          50.62          1.81             0.13            0.02   \n",
       "3          54.50          2.28             0.17            0.03   \n",
       "4          91.27          3.62             0.19            0.04   \n",
       "5          95.80          2.58             0.28            0.10   \n",
       "6         213.46          2.40             0.22            0.07   \n",
       "7         185.09         40.88             0.27            0.15   \n",
       "\n",
       "  param_learning_rate param_depth                                params  \\\n",
       "0                0.10           7    {'learning_rate': 0.1, 'depth': 7}   \n",
       "1                0.15           7   {'learning_rate': 0.15, 'depth': 7}   \n",
       "2                0.10           8    {'learning_rate': 0.1, 'depth': 8}   \n",
       "3                0.15           8   {'learning_rate': 0.15, 'depth': 8}   \n",
       "4                0.10           9    {'learning_rate': 0.1, 'depth': 9}   \n",
       "5                0.15           9   {'learning_rate': 0.15, 'depth': 9}   \n",
       "6                0.10          10   {'learning_rate': 0.1, 'depth': 10}   \n",
       "7                0.15          10  {'learning_rate': 0.15, 'depth': 10}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0               0.24               0.38               0.30               0.39   \n",
       "1               0.26               0.41               0.33               0.42   \n",
       "2               0.25               0.39               0.30               0.40   \n",
       "3               0.26               0.41               0.34               0.43   \n",
       "4               0.25               0.39               0.31               0.40   \n",
       "5               0.27               0.42               0.34               0.42   \n",
       "6               0.26               0.39               0.32               0.40   \n",
       "7               0.27               0.44               0.34               0.44   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.33             0.33            0.05                8  \n",
       "1               0.39             0.36            0.06                4  \n",
       "2               0.35             0.34            0.06                7  \n",
       "3               0.38             0.36            0.06                3  \n",
       "4               0.37             0.34            0.05                6  \n",
       "5               0.39             0.37            0.06                2  \n",
       "6               0.36             0.35            0.05                5  \n",
       "7               0.41             0.38            0.07                1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search2.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed6329",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}